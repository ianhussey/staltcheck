---
title: "STALTcheck: Using the StatCheck dataset to estimate the magnitude of STALT results"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r include=FALSE}

# formatting options
# set default chunk options
knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)

# disable scientific notation
options(scipen = 999) 

```

```{r}

library(tidyverse)
library(metafor)
library(janitor)
library(statcheck)
library(knitr)
library(kableExtra)
library(furrr)

```

# STALTcheck functions

Refactor 'statcheck simple edition' code to get STALT result out of it too.

```{r include=FALSE}

library(dplyr)
library(stringr)
library(statcheck)

CLOSE_RANGE = 0.01 # proportion proximity of computed vs reported p-values to still be considered "close"

# Function to preprocess text and make it more statcheck-friendly
preprocess_text <- function(text) {
  # The edge of paragraph can cause issues
  text <- paste("", text, "")
  
  # Replace weird spaces
  text <- text %>%
    str_replace_all(fixed("â€‰"), " ") %>%  # half spaces
    str_replace_all("\\s", " ") # normalize spaces
  
  # Replace non-standard separators
  text <- text %>%
    str_replace_all(fixed(";"), fixed(",")) %>%
    str_replace_all(fixed("["), fixed("(")) %>%
    str_replace_all(fixed("]"), fixed(")"))
  
  # Replace squared symbol
  text <- text %>% str_replace_all(fixed("\u00B2"), fixed("2"))
  
  # Statcheck has trouble with test_values or p-values that are exactly 0 or 1
  text <- text %>%
    str_replace_all("=\\s?0(?!(\\d|(\\.\\d)))", fixed("= 0.0")) %>%
    str_replace_all("<\\s?0(?!(\\d|(\\.\\d)))", fixed("< 0.0")) %>%
    str_replace_all(">\\s?0(?!(\\d|(\\.\\d)))", fixed("> 0.0")) %>%
    str_replace_all("=\\s?1(?!(\\d|(\\.\\d)))", fixed("= 1.0")) %>%
    str_replace_all("<\\s?1(?!(\\d|(\\.\\d)))", fixed("< 1.0")) %>%
    str_replace_all(">\\s?1(?!(\\d|(\\.\\d)))", fixed("> 1.0"))
  
  # Recognize t-tests without parentheses
  REGEX_NUMBER <- "[0-9]*\\.?[0-9]+" # positive number with optional decimal
  REGEX_T <- paste0("[^A-Za-z](t|T)", REGEX_NUMBER, "\\s*=")
  REGEX_F <- paste0("[^A-Za-z](f|F)", REGEX_NUMBER, ",", REGEX_NUMBER, "\\s*=")
  
  # Add parentheses to smooshed t-tests
  text <- text %>%
    str_replace_all(REGEX_T, function(s) {
      degrees_of_freedom <- str_extract(s, REGEX_NUMBER)
      paste0(" t(", degrees_of_freedom, ")=")
    })
  
  # Add parentheses to smooshed f-tests
  text <- text %>%
    str_replace_all(REGEX_F, function(s) {
      degrees_of_freedom <- str_extract_all(s, REGEX_NUMBER)[[1]]
      paste0(" f(", degrees_of_freedom[[1]], ",", degrees_of_freedom[[2]], ")=")
    })
  
  return(text)
}

# Function to process text, apply statcheck, and return results
process_stat_results <- function(input_text, statcheck_fix = TRUE, check_small_errors = TRUE, check_one_tailed = TRUE) {
  # Optionally preprocess the input text
  if (statcheck_fix) {
    input_text <- preprocess_text(input_text)
  }
  
  # Apply statcheck
  result_table <- statcheck(input_text) 

  if(is.data.frame(result_table)){
    result_table <- result_table|>
      mutate(reported_p = as.numeric(reported_p),
             computed_p = as.numeric(computed_p))
  }
  
  # Clean up columns if statcheck found any results
  if (!is.null(result_table)) {
    result_table <- result_table %>%
      mutate(p_is_close = (abs(reported_p - computed_p) / (reported_p / 2 + computed_p / 2) < CLOSE_RANGE)) %>%
      mutate(p_is_close = p_is_close | abs(reported_p - computed_p) < 0.0001) %>%
      mutate(p_is_close = p_is_close & check_small_errors)
    
    # Clean up and format output
    result_table <- result_table %>%
      mutate(df1 = ifelse(is.na(df1), "-", df1),
             df2 = ifelse(is.na(df2), "-", df2)) %>%
      rowwise() %>%
      mutate(df1 = format(df1, digits = 3, drop0trailing = TRUE),
             df2 = format(df2, digits = 3, drop0trailing = TRUE),
             reported_p_string = format(reported_p, digits = 2, nsmall = 3, drop0trailing = TRUE),
             computed_p_string = format(computed_p, digits = 2, nsmall = 3, drop0trailing = TRUE)) %>%
      ungroup()
    
    # # Return only relevant columns
    # result_table <- result_table %>%
    #   select(test_value, df1, df2, Value, reported_p, computed_p, p_is_close)
  }
  
  return(result_table)
}

```

# Apply to the StatCheck APA dataset

Verify you still get roughtly the same results as the original StatCheck paper.

```{r}

# set up parallel processing
future::plan(multisession)

# dat <- read_rds("../data/data_fulltexts.rds") |>
#   mutate(text = str_remove_all(text, "\n"))
#
# write_rds(dat, "../data/data_fulltexts_no_newlines.rds", compress = "gz")

dat <- read_rds("../data/data_fulltexts_no_newlines.rds")

possible_process_stat_results <- possibly(process_stat_results, otherwise = NA)

```

```{r}

# start_time <- Sys.time()
# 
# statcheck_on_apa_dataset <- dat |>
#   #slice(1:10000) |>
#   mutate(results = future_map(text, possible_process_stat_results)) |>
#   select(-text) |>
#   unnest(results) |>
#   full_join(dat |> select(doi), by = "doi")
# 
# end_time <- Sys.time()
# time_taken <- round(end_time - start_time, 2)
# time_taken
# 
# write_rds(statcheck_on_apa_dataset, "../data/statcheck_on_apa_dataset.rds")
statcheck_on_apa_dataset <- read_rds("../data/statcheck_on_apa_dataset.rds")

```

```{r}

statcheck_on_apa_dataset |>
  distinct(doi) |>
  count(name = "n_dois")

statcheck_on_apa_dataset |>
  drop_na(decision_error) |>
  distinct(doi) |>
  count(name = "n_decision_error")

statcheck_on_apa_dataset |>
  drop_na(decision_error) |>
  group_by(doi) |>
  summarize(decision_error = max(decision_error, na.rm = TRUE)) |>
  ungroup() |>
  count(decision_error, name = "n_dois_with_decision_errors") |>
  mutate(percent = janitor::round_half_up(n_dois_with_decision_errors / sum(n_dois_with_decision_errors)*100, 1)) |>
  kable(align = "r") |>
  kable_classic(full_width = FALSE)

```

- n articles: 74470
- n articles with statcheck-able results detected: 26769
- n articles with 1+ statcheck decision errors: 3446, 12.9% (broadly replicates Nuijten et al.'s result)

# STALTcheck errors

## Z score

```{r fig.height=4, fig.width=10}

# is_lower <- function(value, threshold = 0.0000000000000001){
#   tolerance <- threshold * -1
#   (value - threshold) < -tolerance
# }

staltcheck_on_apa_database <- statcheck_on_apa_dataset |> 
  filter(!is.na(computed_p)) |>
  mutate(z_score = qnorm(log(computed_p / 2), lower.tail = FALSE, log.p = TRUE))

ggplot(staltcheck_on_apa_database, aes(z_score)) +
  geom_histogram(boundary = 0, binwidth = 0.25) +
  scale_x_continuous(breaks = c(0, 1.96, 2.58, 3.29, 3.89, 10, 20, 30, 40),
                     labels = c("(p = 1) 0", "(p < .05) 1.96", "(p < .01) 2.58", "(p < .001) 3.29", "(p < .0001) 3.89", "(p ~ 10e-23) 10", "(p ~ 10e-88) 20", "(p ~ 10e-197) 30", "(p ~ 10e-351) 40")) +
  geom_vline(xintercept = 1.960, linetype = "dotted") + # p < .05
  geom_vline(xintercept = 2.576, linetype = "dotted") + # p < .01
  geom_vline(xintercept = 3.291, linetype = "dotted") + # p < .001
  geom_vline(xintercept = 3.891, linetype = "dotted") + # p < .0001
  theme_linedraw() +
  ylab("Frequency") +
  xlab("Z score") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

```

```{r fig.height=8, fig.width=10}

ggplot(staltcheck_on_apa_database, aes(z_score)) +
  geom_histogram(boundary = 0, binwidth = 0.25) +
  scale_x_continuous(breaks = c(0, 1.96, 2.58, 3.29, 3.89, 10, 20, 30, 40),
                     labels = c("(p = 1) 0", "(p < .05) 1.96", "(p < .01) 2.58", "(p < .001) 3.29", "(p < .0001) 3.89", "(p ~ 10e-23) 10", "(p ~ 10e-88) 20", "(p ~ 10e-197) 30", "(p ~ 10e-351) 40")) +
  geom_vline(xintercept = 1.960, linetype = "dotted") + # p < .05
  geom_vline(xintercept = 2.576, linetype = "dotted") + # p < .01
  geom_vline(xintercept = 3.291, linetype = "dotted") + # p < .001
  geom_vline(xintercept = 3.891, linetype = "dotted") + # p < .0001
  theme_linedraw() +
  ylab("Frequency") +
  xlab("Z score") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  facet_wrap(~ error, ncol = 1, scales = "free_y")

```

## log(Z score)

```{r}

ggplot(staltcheck_on_apa_database, aes(log(z_score))) +
  geom_histogram(boundary = 0, binwidth = 0.1) +
  scale_x_continuous(breaks = log(c(0, 1.96, 2.58, 3.29, 3.89, 10, 20, 30, 40)),
                     labels = c("p = 1", "p < .05", "p < .01", "p < .001", "p < .0001", "p ~ 10e-23", "p ~ 10e-88", "p ~ 10e-197", "p ~ 10e-351")) +
  geom_vline(xintercept = log(1.960), linetype = "dotted") + # p < .05
  geom_vline(xintercept = log(2.576), linetype = "dotted") + # p < .01
  geom_vline(xintercept = log(3.291), linetype = "dotted") + # p < .001
  geom_vline(xintercept = log(3.891), linetype = "dotted") + # p < .0001
  theme_linedraw() +
  ylab("Frequency") +
  xlab("log(Z score)") +
  coord_cartesian(xlim = c(-5, 5)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

ggplot(staltcheck_on_apa_database, aes(log(z_score))) +
  geom_histogram(boundary = 0, binwidth = 0.1) +
  scale_x_continuous(breaks = log(c(0, 1.96, 2.58, 3.29, 3.89, 10, 20, 30, 40)),
                     labels = c("p = 1", "p < .05", "p < .01", "p < .001", "p < .0001", "p ~ 10e-23", "p ~ 10e-88", "p ~ 10e-197", "p ~ 10e-351")) +
  geom_vline(xintercept = log(1.960), linetype = "dotted") + # p < .05
  geom_vline(xintercept = log(2.576), linetype = "dotted") + # p < .01
  geom_vline(xintercept = log(3.291), linetype = "dotted") + # p < .001
  geom_vline(xintercept = log(3.891), linetype = "dotted") + # p < .0001
  theme_linedraw() +
  ylab("Frequency") +
  xlab("log(Z score)") +
  coord_cartesian(xlim = c(-5, 5)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  facet_wrap(~ error, ncol = 1, scales = "free_y")

```

## Percentiles 

```{r}

value_at_percentile <- function(empirical_distribution, percentile) {
  # Use the quantile function to find the value at the given percentile
  value <- quantile(empirical_distribution, probs = percentile / 100)
  return(value)
}

z_to_p <- function(z_score) {
  # Calculate the p-value for a two-tailed test using log.p to handle very small p-values
  log_p_value <- pnorm(abs(z_score), lower.tail = FALSE, log.p = TRUE) + log(2)
  
  # Exponentiate the result to convert the log p-value to the actual p-value
  p_value <- exp(log_p_value)
  
  return(p_value)
}

convert_to_scientific <- function(num) {
  return(format(num, scientific = TRUE))
}

tibble(percentile = seq(90, 100, 1)) %>%
  mutate(p = value_at_percentile(staltcheck_on_apa_database$z_score, percentile) |>
           z_to_p() |>
           convert_to_scientific()) |>
  kable(align = "r") |>
  kable_classic(full_width = FALSE)

tibble(percentile = seq(90, 100, 1)) %>%
  mutate(p = value_at_percentile(staltcheck_on_apa_database |>
                                   filter(error) |>
                                   pull(z_score), percentile) |>
           z_to_p() |>
           convert_to_scientific()) |>
  rename(percentile_errors = percentile) |>
  kable(align = "r") |>
  kable_classic(full_width = FALSE)

tibble(percentile = seq(90, 100, 1)) %>%
  mutate(p = value_at_percentile(staltcheck_on_apa_database |>
                                   filter(!error) |>
                                   pull(z_score), percentile) |>
           z_to_p() |>
           convert_to_scientific()) |>
  rename(percentile_nonerrors = percentile) |>
  kable(align = "r") |>
  kable_classic(full_width = FALSE)

```

95th percentile Z score: `r value_at_percentile(staltcheck_on_apa_database$z_score, 95)`

## Percentile rank

Function to check what percentile a given Z score is in. Uses 12.18249 as an example (I can't remember where I got the number).

```{r}

percentile_rank <- function(empirical_distribution, value) {
  # Calculate the proportion of values in the empirical distribution
  # that are less than or equal to the given value
  percentile <- mean(empirical_distribution <= value) * 100
  return(percentile)
}

percentile_rank(staltcheck_on_apa_database$z_score, 12.18249) # log(z) = 2.5

```

# Scrap

```{r}

# computed_p = format(computed_p, scientific = TRUE),

statcheck_on_apa_dataset |>
  mutate(log_p_by_minus_1 = log(computed_p) * -1) |>
  ggplot(aes(log_p_by_minus_1)) +
  geom_histogram(boundary = 0, binwidth = 5) 


statcheck_on_apa_dataset |>
  ggplot(aes(computed_p)) +
  geom_histogram(boundary = 0, binwidth = 0.001)

# statcheck_on_apa_dataset |>
#   mutate(log_p_by_minus_1_truncated = log(computed_p_truncated) * -1) |>
#   ggplot(aes(log_p_by_minus_1_truncated)) +
#   geom_histogram(boundary = 0, binwidth = 5) 


res_summary <- statcheck_on_apa_dataset |>
  mutate(log_p_by_minus_1 = log(computed_p) * -1) |>
  count(log_p_by_minus_1) |>
  mutate(percent = n / sum(n) * 100)

```



